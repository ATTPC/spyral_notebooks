{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Clusters\n",
    "\n",
    "This notebook is for examining the clustering algorithm used by Spyral. To use this notebook you *must* first have run the PointcloudPhase of Spyral and generated those results. The clustering algorithm will be applied to the point clouds and plots will be displayed showing the results. This is useful for tuning the various clustering parameters. Note that data generated here is NOT saved. This is only for testing. For more informations on phases checkout the [documentation](https://attpc.github.io/Spyral/).\n",
    "\n",
    "## Configuration\n",
    "First we import all the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyral.core.point_cloud import PointCloud\n",
    "from spyral.core.clusterize import form_clusters, join_clusters, cleanup_clusters\n",
    "from spyral.core.run_stacks import form_run_string\n",
    "from spyral import ClusterParameters\n",
    "\n",
    "from pathlib import Path\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "# Utility for syncing plot colors\n",
    "def get_color(value: int) -> str:\n",
    "    color_index = value\n",
    "    if color_index >= len(DEFAULT_PLOTLY_COLORS):\n",
    "        color_index = color_index % len(DEFAULT_PLOTLY_COLORS)\n",
    "    elif color_index == -1:\n",
    "        return \"black\"\n",
    "    return DEFAULT_PLOTLY_COLORS[color_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the point clouds generated by phase one. This is very similar to the previous example where we loaded traces, so please reference that section if anything is unclear.\n",
    "\n",
    "First load the config and the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters\n",
    "workspace_path = Path(\"/path/to/your/workspace/\")\n",
    "\n",
    "cluster_params = ClusterParameters(\n",
    "    min_cloud_size=50,\n",
    "    min_points=3,\n",
    "    min_size_scale_factor=0.05,\n",
    "    min_size_lower_cutoff=10,\n",
    "    cluster_selection_epsilon=10.0,\n",
    "    min_cluster_size_join=15,\n",
    "    circle_overlap_ratio=0.25,\n",
    "    outlier_scale_factor=0.05,\n",
    ")\n",
    "\n",
    "pointcloud_path = workspace_path / \"Pointcloud\" # this may change if you add custom phases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the workspace to load the point cloud file, creating an event iterator so we can walk through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 16\n",
    "point_file_path = pointcloud_path / f\"{form_run_string(run_number)}.h5\"\n",
    "point_file = h5.File(point_file_path, 'r')\n",
    "\n",
    "cloud_group: h5.Group = point_file.get('cloud')\n",
    "min_event = cloud_group.attrs['min_event']\n",
    "max_event = cloud_group.attrs['max_event']\n",
    "event_iterator = iter(range(min_event, max_event+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Re-runing the code below this cell will allow you to walk through the dataset in order, as long as you do not re-run the cells  above this!\n",
    "\n",
    "Now we'll load the next event in the dataset (or a specific hardcoded one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = next(event_iterator)\n",
    "# You can hardcode a specific event to debug\n",
    "# event = 20567\n",
    "print(f'Event {event}')\n",
    "event_data = cloud_group[f'cloud_{event}']\n",
    "cloud = PointCloud(event_data[:].copy(), event)\n",
    "print(f'Cloud size: {len(cloud)}')\n",
    "\n",
    "fig = make_subplots(2,1,specs=[[{\"type\": \"scene\"}],[{\"type\": \"xy\"}]],row_heights=[0.6,0.4])\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=cloud.data[:, 2], \n",
    "        y=cloud.data[:, 0], \n",
    "        z=cloud.data[:, 1], \n",
    "        mode=\"markers\", \n",
    "        marker= {\n",
    "            \"size\": 3, \n",
    "            \"color\": cloud.data[:, 3], \n",
    "            \"showscale\": True\n",
    "        }, \n",
    "        name=\"Point Cloud\"\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.linalg.norm(cloud.data[:, :3], axis=1), y=cloud.data[:, 4], mode=\"markers\", name=\"Charge\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Distance (mm)\",\n",
    "    yaxis_title=\"Integrated Charge\",\n",
    "    scene = {\n",
    "        \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    width=1300,\n",
    "    height=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see two plots. One is the 3-D point cloud and the other is the integrated charge on the pad as a function of distance (a proxy of the Bragg Curve). These are essentially the feautres we will be clustering on. Now lets cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, labels = form_clusters(cloud, cluster_params)\n",
    "total_points = 0\n",
    "for cluster in clusters:\n",
    "    total_points += len(cluster.point_cloud)\n",
    "print(f\"Total non-noise points: {total_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the clusters together to check the performance of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(2,1,specs=[[{\"type\": \"scene\"}],[{\"type\": \"xy\"}]],row_heights=[0.6,0.4])\n",
    "scaled_data = np.zeros((len(cluster.point_cloud.data), 3))\n",
    "for cluster in clusters:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster.point_cloud.data[:, 2], \n",
    "            y=cluster.point_cloud.data[:, 0], \n",
    "            z=cluster.point_cloud.data[:, 1], \n",
    "            mode=\"markers\",\n",
    "            legendgroup=\"clusters\",\n",
    "            marker= {\n",
    "                \"size\": 3,\n",
    "                \"color\": get_color(cluster.label)\n",
    "            }, \n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.linalg.norm(cluster.point_cloud.data[:, :3], axis=1), \n",
    "            y=cluster.point_cloud.data[:, 3], \n",
    "            legendgroup=\"clusters\",\n",
    "            mode=\"markers\",\n",
    "            marker= {\n",
    "                \"color\": get_color(cluster.label)\n",
    "            },\n",
    "            showlegend=False,\n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1\n",
    "    )\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Distance (mm)\",\n",
    "    yaxis_title=\"Integrated Charge\",\n",
    "    scene = {\n",
    "        \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    width=1300,\n",
    "    height=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows the different clusters identified by the algorithm, with the labels supplied by the algorithm. Points labeled -1 were identified to be noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically the algorithm breaks trajectories into many clusters due to varying pad denisty, trajectory gaps, etc. So we need to rejoin these cluster pieces into an actual trajectory cluster. We do this by fitting a circle to each cluster and seeing how much the circles overlap. If they overlap enough, they are deemed to be from the same trajectory. Clusters are joined until no more joins are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_clusters, labels = join_clusters(clusters, cluster_params, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can again plot our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(2,1,specs=[[{\"type\": \"scene\"}],[{\"type\": \"xy\"}]],row_heights=[0.6,0.4])\n",
    "for cluster in joined_clusters:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster.point_cloud.data[:, 2], \n",
    "            y=cluster.point_cloud.data[:, 0], \n",
    "            z=cluster.point_cloud.data[:, 1], \n",
    "            mode=\"markers\",\n",
    "            legendgroup=\"clusters\",\n",
    "            marker= {\n",
    "                \"size\": 3,\n",
    "                \"color\": get_color(cluster.label)\n",
    "            }, \n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.linalg.norm(cluster.point_cloud.data[:, :3], axis=1), \n",
    "            y=cluster.point_cloud.data[:, 4],\n",
    "            legendgroup=\"clusters\",\n",
    "            mode=\"markers\",\n",
    "            marker= {\n",
    "                \"color\": get_color(cluster.label)\n",
    "            },\n",
    "            showlegend=False,\n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1\n",
    "    )\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Distance (mm)\",\n",
    "    yaxis_title=\"Integrated Charge\",\n",
    "    scene = {\n",
    "        \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    width=1300,\n",
    "    height=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see well defined trajectory clusters! If you don't, try tweaking some of the parameters or cycling to a different point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a cleanup pass is run on the joined clusters to reduce noise. Note that we change types here. Previously our clusters were of type LabeledCloud, a temporary holding type. Now our clusters are of type Cluster, so the semantics change a small amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_clusters, labels = cleanup_clusters(joined_clusters, cluster_params, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again plot our projections to examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(2,1,specs=[[{\"type\": \"scene\"}],[{\"type\": \"xy\"}]],row_heights=[0.6,0.4])\n",
    "for cluster in cleaned_clusters:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster.data[:, 2], \n",
    "            y=cluster.data[:, 0], \n",
    "            z=cluster.data[:, 1], \n",
    "            mode=\"markers\",\n",
    "            legendgroup=\"clusters\",\n",
    "            marker= {\n",
    "                \"size\": 3,\n",
    "                \"color\": get_color(cluster.label)\n",
    "            }, \n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.linalg.norm(cluster.data[:, :3], axis=1), \n",
    "            y=cluster.data[:, 3],\n",
    "            legendgroup=\"clusters\",\n",
    "            mode=\"markers\",\n",
    "            marker= {\n",
    "                \"color\": get_color(cluster.label)\n",
    "            },\n",
    "            showlegend=False,\n",
    "            name=f\"Cluster {cluster.label}\"\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1\n",
    "    )\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Distance (mm)\",\n",
    "    yaxis_title=\"Integrated Charge\",\n",
    "    scene = {\n",
    "        \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    width=1300,\n",
    "    height=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you re-run the cells in the Analysis section, you'll walk through the dataset in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We've now generated clusters from our point clouds and tested the parameters, so now you can take these parameters and run the full phase 2 analysis. The next step is perfom basic physics analysis and estimate some pararameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
