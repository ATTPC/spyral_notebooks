{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Clusters\n",
    "\n",
    "This notebook is for examining the clustering algorithm used by Spyral. To use this notebook you *must* first have run the PointcloudPhase of Spyral and generated those results. The clustering algorithm will be applied to the point clouds and plots will be displayed showing the results. This is useful for tuning the various clustering parameters. Note that data generated here is NOT saved. This is only for testing. For more informations on phases checkout the [documentation](https://attpc.github.io/Spyral/).\n",
    "\n",
    "## Configuration\n",
    "First we import all the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyral.core.point_cloud import PointCloud\n",
    "from spyral.core.clusterize import form_clusters, join_clusters, cleanup_clusters\n",
    "from spyral.core.run_stacks import form_run_string\n",
    "from spyral import ClusterParameters\n",
    "\n",
    "from pathlib import Path\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEFAULT_COLORS = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# Utility for syncing plot colors\n",
    "def get_color(value: int) -> str:\n",
    "    color_index = value\n",
    "    if color_index >= len(DEFAULT_COLORS):\n",
    "        color_index = color_index % len(DEFAULT_COLORS)\n",
    "    elif color_index == -1:\n",
    "        return \"black\"\n",
    "    return DEFAULT_COLORS[color_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the point clouds generated by phase one. This is very similar to the previous example where we loaded traces, so please reference that section if anything is unclear.\n",
    "\n",
    "First load the config and the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters\n",
    "workspace_path = Path(\"/path/to/your/workspace/\")\n",
    "\n",
    "cluster_params = ClusterParameters(\n",
    "    min_cloud_size=50,\n",
    "    min_points=3,\n",
    "    min_size_scale_factor=0.05,\n",
    "    min_size_lower_cutoff=10,\n",
    "    cluster_selection_epsilon=10.0,\n",
    "    join_radius_threshold=20.0,\n",
    "    join_z_threshold=50.0,\n",
    "    outlier_scale_factor=0.05,\n",
    ")\n",
    "\n",
    "pointcloud_path = workspace_path / \"Pointcloud\" # this may change if you add custom phases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the workspace to load the point cloud file, creating an event iterator so we can walk through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 16\n",
    "point_file_path = pointcloud_path / f\"{form_run_string(run_number)}.h5\"\n",
    "point_file = h5.File(point_file_path, 'r')\n",
    "\n",
    "cloud_group: h5.Group = point_file.get('cloud')\n",
    "min_event = cloud_group.attrs['min_event']\n",
    "max_event = cloud_group.attrs['max_event']\n",
    "event_iterator = iter(range(min_event, max_event+1))\n",
    "print(f\"First event: {min_event} Last event: {max_event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Re-runing the code below this cell will allow you to walk through the dataset in order, as long as you do not re-run the cells  above this!\n",
    "\n",
    "Now we'll load the next event in the dataset (or a specific hardcoded one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = None\n",
    "# You can hardcode a specific event to debug\n",
    "# event = 241 \n",
    "if event is None:\n",
    "    try:\n",
    "        event = next(event_iterator)\n",
    "    except StopIteration:\n",
    "        raise Exception(\"You ran out of events (wow!) for this file! Select a new file to analyze.\")\n",
    "print(f'Event {event}')\n",
    "event_name = f\"cloud_{event}\"\n",
    "if not event_name in cloud_group:\n",
    "    raise Exception(\"This was a downscale beam event and has been removed from the analysis! Run this cell again to select a new event.\")\n",
    "event_data = cloud_group[f'cloud_{event}']\n",
    "cloud = PointCloud(event, event_data[:].copy())\n",
    "print(f'Cloud size: {len(cloud)}')\n",
    "# Close any open plots to avoid memory problems\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AAB\n",
    "    \"\"\",\n",
    "    per_subplot_kw={\n",
    "        \"A\": {\n",
    "            \"projection\": \"3d\", \n",
    "            \"box_aspect\": (2,1,1),\n",
    "            \"aspect\": \"equalxy\"\n",
    "        }\n",
    "    },\n",
    "    figsize=(15.0, 5.0),\n",
    "    constrained_layout=True\n",
    ")\n",
    "axs[\"A\"].scatter(cloud.data[:, 2], cloud.data[:, 0], cloud.data[:, 1], c=cloud.data[:, 3], s=3, label=\"Pointcloud\")\n",
    "axs[\"A\"].set_xlim3d(0., 1000.0)\n",
    "axs[\"A\"].set_xlabel(\"Z(mm)\")\n",
    "axs[\"A\"].set_ylim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_ylabel(\"X(mm)\")\n",
    "axs[\"A\"].set_zlim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_zlabel(\"Y(mm)\")\n",
    "axs[\"B\"].scatter(cloud.data[:, 0], cloud.data[:, 1], c=cloud.data[:, 3], s=3)\n",
    "axs[\"B\"].set_xlim(-300.0, 300.0)\n",
    "axs[\"B\"].set_xlabel(\"X(mm)\")\n",
    "axs[\"B\"].set_ylim(-300.0, 300.0)\n",
    "axs[\"B\"].set_ylabel(\"Y(mm)\")\n",
    "axs[\"B\"].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see two plots, one is the 3-D point cloud and the other is the pad plane projection. In the next cell we'll apply HDBSCAN to the data and cluster it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, labels = form_clusters(cloud, cluster_params)\n",
    "total_points = 0\n",
    "for cluster in clusters:\n",
    "    total_points += len(cluster.point_cloud)\n",
    "print(f\"Total non-noise points: {total_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the clusters together to check the performance of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AAB\n",
    "    \"\"\",\n",
    "    per_subplot_kw={\n",
    "        \"A\": {\n",
    "            \"projection\": \"3d\", \n",
    "            \"box_aspect\": (2,1,1),\n",
    "            \"aspect\": \"equalxy\"\n",
    "        }\n",
    "    },\n",
    "    figsize=(15.0, 5.0),\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for cluster in clusters:\n",
    "    axs[\"A\"].scatter(cluster.point_cloud.data[:, 2], cluster.point_cloud.data[:, 0], cluster.point_cloud.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "    axs[\"B\"].scatter(cluster.point_cloud.data[:, 0], cluster.point_cloud.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "axs[\"A\"].set_xlim3d(0., 1000.0)\n",
    "axs[\"A\"].set_xlabel(\"Z(mm)\")\n",
    "axs[\"A\"].set_ylim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_ylabel(\"X(mm)\")\n",
    "axs[\"A\"].set_zlim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_zlabel(\"Y(mm)\")\n",
    "axs[\"B\"].set_xlim(-300.0, 300.0)\n",
    "axs[\"B\"].set_xlabel(\"X(mm)\")\n",
    "axs[\"B\"].set_ylim(-300.0, 300.0)\n",
    "axs[\"B\"].set_ylabel(\"Y(mm)\")\n",
    "axs[\"B\"].grid()\n",
    "axs[\"A\"].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows the different clusters identified by the algorithm, with the labels supplied by the algorithm. Points labeled -1 were identified to be noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically the algorithm breaks trajectories into many clusters due to varying pad denisty, trajectory gaps, etc. So we need to rejoin these cluster pieces into an actual trajectory cluster. We do this by fitting a circle to each cluster and seeing how much the circles overlap. If they overlap enough, they are deemed to be from the same trajectory. Clusters are joined until no more joins are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_clusters, labels = join_clusters(clusters, cluster_params, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can again plot our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AAB\n",
    "    \"\"\",\n",
    "    per_subplot_kw={\n",
    "        \"A\": {\n",
    "            \"projection\": \"3d\", \n",
    "            \"box_aspect\": (2,1,1),\n",
    "            \"aspect\": \"equalxy\"\n",
    "        }\n",
    "    },\n",
    "    figsize=(15.0, 5.0),\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for cluster in joined_clusters:\n",
    "    axs[\"A\"].scatter(cluster.point_cloud.data[:, 2], cluster.point_cloud.data[:, 0], cluster.point_cloud.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "    axs[\"B\"].scatter(cluster.point_cloud.data[:, 0], cluster.point_cloud.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "axs[\"A\"].set_xlim3d(0., 1000.0)\n",
    "axs[\"A\"].set_xlabel(\"Z(mm)\")\n",
    "axs[\"A\"].set_ylim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_ylabel(\"X(mm)\")\n",
    "axs[\"A\"].set_zlim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_zlabel(\"Y(mm)\")\n",
    "axs[\"B\"].set_xlim(-300.0, 300.0)\n",
    "axs[\"B\"].set_xlabel(\"X(mm)\")\n",
    "axs[\"B\"].set_ylim(-300.0, 300.0)\n",
    "axs[\"B\"].set_ylabel(\"Y(mm)\")\n",
    "axs[\"B\"].grid()\n",
    "axs[\"A\"].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see well defined trajectory clusters! If you don't, try tweaking some of the parameters or cycling to a different point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a cleanup pass is run on the joined clusters to reduce noise. Note that we change types here. Previously our clusters were of type LabeledCloud, a temporary holding type. Now our clusters are of type Cluster, so the semantics change a small amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_clusters, labels = cleanup_clusters(joined_clusters, cluster_params, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again plot our projections to examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AAB\n",
    "    \"\"\",\n",
    "    per_subplot_kw={\n",
    "        \"A\": {\n",
    "            \"projection\": \"3d\", \n",
    "            \"box_aspect\": (2,1,1),\n",
    "            \"aspect\": \"equalxy\"\n",
    "        }\n",
    "    },\n",
    "    figsize=(15.0, 5.0),\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for cluster in cleaned_clusters:\n",
    "    axs[\"A\"].scatter(cluster.data[:, 2], cluster.data[:, 0], cluster.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "    axs[\"B\"].scatter(cluster.data[:, 0], cluster.data[:, 1], c=get_color(cluster.label), s=3, label=f\"Cluster {cluster.label}\")\n",
    "axs[\"A\"].set_xlim3d(0., 1000.0)\n",
    "axs[\"A\"].set_xlabel(\"Z(mm)\")\n",
    "axs[\"A\"].set_ylim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_ylabel(\"X(mm)\")\n",
    "axs[\"A\"].set_zlim3d(-300.0, 300.0)\n",
    "axs[\"A\"].set_zlabel(\"Y(mm)\")\n",
    "axs[\"B\"].set_xlim(-300.0, 300.0)\n",
    "axs[\"B\"].set_xlabel(\"X(mm)\")\n",
    "axs[\"B\"].set_ylim(-300.0, 300.0)\n",
    "axs[\"B\"].set_ylabel(\"Y(mm)\")\n",
    "axs[\"B\"].grid()\n",
    "axs[\"A\"].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you re-run the cells in the Analysis section, you'll walk through the dataset in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We've now generated clusters from our point clouds and tested the parameters, so now you can take these parameters and run the full phase 2 analysis. The next step is perfom basic physics analysis and estimate some pararameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
