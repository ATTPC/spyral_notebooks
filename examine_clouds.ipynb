{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Point Clouds\n",
    "\n",
    "This notebook walks through the first default phase of a Spyral pipeline, `PointcloudPhase`. For documentation on the phases, follow this [link](https://attpc.github.io/Spyral/user_guide/phases/about/) to the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First we import all of the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyral.core.point_cloud import point_cloud_from_get, calibrate_point_cloud_z\n",
    "from spyral.core.run_stacks import form_run_string\n",
    "from spyral.trace.get_event import GetEvent, GET_DATA_TRACE_START, GET_DATA_TRACE_STOP\n",
    "from spyral.trace.trace_reader import create_reader\n",
    "from spyral.correction import create_electron_corrector\n",
    "from spyral.core.pad_map import PadMap\n",
    "\n",
    "from spyral import PadParameters, GetParameters, FribParameters, DetectorParameters, DEFAULT_MAP, PointcloudPhase \n",
    "\n",
    "import numpy.random as random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def find_trace_from_padid(event: GetEvent, pad_id: int) -> int:\n",
    "    for idx, trace in enumerate(event.traces):\n",
    "        if trace.hw_id.pad_id == pad_id:\n",
    "            return idx\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Define your Spyral configuration below. If you aren't sure what some of these values mean, they are all documented at the [Spyral documentation](https://attpc.github.io/Spyral/user_guide/config/about/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your data\n",
    "trace_path = Path(\"/path/to/raw/attpc/traces/\")\n",
    "workspace_path = Path(\"/path/to/your/workspace/\")\n",
    "\n",
    "# Pad mapping. We use defaults here\n",
    "pad_params = PadParameters(\n",
    "    pad_geometry_path=DEFAULT_MAP,\n",
    "    pad_time_path=DEFAULT_MAP,\n",
    "    pad_electronics_path=DEFAULT_MAP,\n",
    "    pad_scale_path=DEFAULT_MAP,\n",
    ")\n",
    "\n",
    "# AT-TPC GET trace analysis\n",
    "get_params = GetParameters(\n",
    "    baseline_window_scale=20.0,\n",
    "    peak_separation=50.0,\n",
    "    peak_prominence=20.0,\n",
    "    peak_max_width=50.0,\n",
    "    peak_threshold=40.0,\n",
    ")\n",
    "\n",
    "# AT-TPC FRIBDAQ trace analysis\n",
    "frib_params = FribParameters(\n",
    "    baseline_window_scale=100.0,\n",
    "    peak_separation=50.0,\n",
    "    peak_prominence=20.0,\n",
    "    peak_max_width=500.0,\n",
    "    peak_threshold=100.0,\n",
    "    ic_delay_time_bucket=1100,\n",
    "    ic_multiplicity=1,\n",
    ")\n",
    "\n",
    "# Detector properties\n",
    "det_params = DetectorParameters(\n",
    "    magnetic_field=2.85,\n",
    "    electric_field=45000.0,\n",
    "    detector_length=1000.0,\n",
    "    beam_region_radius=25.0,\n",
    "    micromegas_time_bucket=10.0,\n",
    "    window_time_bucket=560.0,\n",
    "    get_frequency=6.25,\n",
    "    garfield_file_path=Path(\"/path/to/some/garfield.txt\"),\n",
    "    do_garfield_correction=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Data \n",
    "\n",
    "Now that our configuration is loaded, we can start reading and analyzing some data. Step one is to access the raw trace datafile. This means that you need to pick a run to analyze; we store the run number in a variable for later reference. To analyze a different run simply change the run number. \n",
    "\n",
    "Traces come in some different formats from tools like [attpc_merger](https://github.com/ATTPC/attpc_merger) or [harmonizer](https://github.com/ATTPC/harmonizer). We use the TraceReader protocol to handle which format we're looking at. The `create_reader` function choses the appropriate implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 16 # pick a run\n",
    "trace_file_path = trace_path / f\"{form_run_string(run_number)}.h5\"\n",
    "trace_reader = create_reader(trace_file_path, run_number)\n",
    "if trace_reader is None:\n",
    "    raise Exception(\"Invalid Reader! Make sure the traces exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll setup an iterator so we can walk through the events in the file. This will allow us to walk through events in order. Only run this code block **ONCE**. If you run it again you'll start the iterator over and just keep looking at the first event! We'll also load some assets here that we'll use later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the trace file for the range of events, and make an iterator\n",
    "event_iterator = iter(trace_reader.event_range())\n",
    "rng = random.default_rng()\n",
    "phase = PointcloudPhase(get_params, frib_params, det_params, pad_params)\n",
    "phase.create_assets(workspace_path)\n",
    "correction_path = phase.electron_correction_path\n",
    "pad_map = PadMap(pad_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing\n",
    "\n",
    "Everything below this section can be run repeatedly to walk through the data sequentially.\n",
    "\n",
    "We retrieve the next event in the file (or the current hardcoded event if you want) and do some signal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_number = next(event_iterator)\n",
    "# You can also hardcode an event number here!\n",
    "# event_number = 1\n",
    "print(f\"Analzying event: {event_number}\")\n",
    "event = trace_reader.read_event(event_number, get_params, frib_params, rng) # The signal-analyzed event\n",
    "raw_event_data = trace_reader.read_raw_get_event(event_number) # The raw GET data for comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll look at the signal analysis on a random trace within the event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_number = random.randint(0, len(raw_event_data))\n",
    "# trace_number = find_trace_from_padid(event, 397)\n",
    "raw_trace_data = raw_event_data[trace_number]\n",
    "time_bucket_range = np.arange(start=0, stop=512)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=time_bucket_range, y=raw_trace_data[GET_DATA_TRACE_START:GET_DATA_TRACE_STOP], mode=\"lines\", name=f\"Raw Trace {trace_number}\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=time_bucket_range, y=event.traces[trace_number].trace, mode=\"lines\",name=f\"Baseline Corrected Trace {trace_number}\")\n",
    ")\n",
    "print(f\"Trace Number: {trace_number}\")\n",
    "print(f\"Trace Hardware: {event.traces[trace_number].hw_id}\")\n",
    "peak_amps = []\n",
    "peak_cents = []\n",
    "peak_left = []\n",
    "peak_left_amps = []\n",
    "peak_right = []\n",
    "peak_right_amps = []\n",
    "for peak in event.traces[trace_number].get_peaks():\n",
    "    peak_amps.append(peak.amplitude)\n",
    "    peak_cents.append(np.floor(peak.centroid))\n",
    "    peak_left.append(peak.positive_inflection)\n",
    "    peak_right.append(peak.negative_inflection)\n",
    "    peak_left_amps.append(event.traces[trace_number].trace[int(peak.positive_inflection)])\n",
    "    peak_right_amps.append(event.traces[trace_number].trace[int(peak.negative_inflection)])\n",
    "print(f\"Peak centroids: {peak_cents}\")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=peak_cents, y=peak_amps, mode=\"markers\", name=\"Peaks\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=peak_left, y=peak_left_amps, mode=\"markers\", name=\"Peak Left Edges\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=peak_right, y=peak_right_amps, mode=\"markers\", name=\"Peak Right Edges\")\n",
    ")\n",
    "fig.update_legends()\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Time Bucket\",\n",
    "    yaxis_title=\"Amplitude\",\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see the plot of the raw trace as well as the baseline corrected trace. The baseline corrected trace is computed using a low-pass filter. The peaks are labeled with their centroids and left and right edges. To look at different traces, you can run the above cell over and over again; it will select a random trace in the event each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our signals, we will use the pad information (x, y) and the signal time (time bucket) to create a 3-D image of the whole event, called a PointCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = point_cloud_from_get(event.get, pad_map)\n",
    "hover_text = [f\"Pad ID: {int(point[5])}\" for point in cloud.data] # We'll use this later\n",
    "\n",
    "fig = make_subplots(2, 1, row_heights=[0.66, 0.33], specs=[[{\"type\": \"xy\"}], [{\"type\": \"scene\"}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=cloud.data[:, 2], \n",
    "        y=cloud.data[:, 0], \n",
    "        z=cloud.data[:, 1], \n",
    "        mode=\"markers\",\n",
    "        text = hover_text,\n",
    "        hovertemplate=\"X: %{y:.2f}<br>Y: %{z:.2f}<br>Z: %{x:.2f}<br>%{text}\",\n",
    "        marker= {\n",
    "            \"size\": 3, \n",
    "            \"color\": cloud.data[:, 3], \n",
    "            \"showscale\": True\n",
    "            }, \n",
    "        name=\"Point Cloud\"\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cloud.data[:, 0], \n",
    "        y=cloud.data[:, 1], \n",
    "        mode=\"markers\",\n",
    "        text = hover_text,\n",
    "        hovertemplate=\"X: %{x:.2f}<br>Y: %{y:.2f}<br>%{text}\",\n",
    "        marker= {\n",
    "            \"color\": cloud.data[:, 3], \n",
    "            \"showscale\": True\n",
    "        }, \n",
    "        name=\"XY Projection\"),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title = \"X (mm)\",\n",
    "    yaxis_title = \"Y (mm)\",\n",
    "    xaxis_range=[-300.0, 300.0],\n",
    "    yaxis_range=[-300.0, 300.0],\n",
    "    scene = {\n",
    "        \"xaxis_title\": \"Z (Time Buckets)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        },\n",
    "        \"xaxis_range\": [0.0, 512.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "    },\n",
    "    width = 1000,\n",
    "    height = 1500,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you should see your point cloud plotted in 3D as well as the X-Y plane (pad plane) projection. The marker color indicates the charge ampltiude of the peak used to make the point in the point cloud. If you hover over one of the points in either plot, you'll see a label which shows the coordinate position as well as the trace and peak number which produced the point. This can be used to pick specific traces to examine\n",
    "\n",
    "The z-axis is still in Time Buckets. We would like to convert this time axis into a position. To do this we use the reference time of the window and micromegas mesh (i.e. the position of the ends of the detector within the trigger). These values have to be estimated from the data. Typically this is handled by looking for window events (events where the beam reacted with the window), because they typically span the entire volume of the detector. Once you've set these values in your config, run the cell below to re-plot the point cloud with calibrated z-position.\n",
    "\n",
    "When calibrating we also apply an electric field correction from a Garfield++ simulation of the AT-TPC electric field. This allows us to correct for field non-uniformities, particularly near the edges of the AT-TPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the correction if requested\n",
    "corrector = None\n",
    "if correction_path.exists():\n",
    "    corrector = create_electron_corrector(correction_path)\n",
    "\n",
    "calibrate_point_cloud_z(cloud, det_params, efield_correction=corrector)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=cloud.data[:, 2], \n",
    "        y=cloud.data[:, 0], \n",
    "        z=cloud.data[:, 1], \n",
    "        mode=\"markers\", \n",
    "        marker= {\n",
    "            \"size\": 3, \n",
    "            \"color\": cloud.data[:, 4], \n",
    "            \"showscale\": True\n",
    "        }, \n",
    "        name=\"Point Cloud\"\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    scene = {\n",
    "        \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    height=750,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still more you can look at however. You can even plot some interesting physics! Below is an example intended to try and plot a Bragg curve from the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot r-Charge projection\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.linalg.norm(cloud.data[:, :3], axis=1), y=cloud.data[:, 4], mode=\"markers\", marker={\"size\": 5})\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Position (mm)\",\n",
    "    yaxis_title=\"Integral\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can re-run the code cells in this Analyzing section to walk through the data sequentially, or select a specific event to look at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That is a basic analysis of the traces and the point cloud data! With well tuned parameters, you're now ready to run the phase 1 analysis. Follow the instructions in the README to do this. Once thats done, you can move on to the next stage, generating and identifying clusters within the point clouds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
